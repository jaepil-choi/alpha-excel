# Alpha Excel - Product Requirement Document (PRD)

## 1.1. ê°œìš”

### ì œí’ˆ ë¹„ì „

**alpha-excel**ì€ í€€íŠ¸ ë¦¬ì„œì²˜ë¥¼ ìœ„í•œ pandas ê¸°ë°˜ ì‹œê·¸ë„ ìƒì„± ë° ë°±í…ŒìŠ¤íŠ¸ ì—”ì§„ì…ë‹ˆë‹¤. Excelì²˜ëŸ¼ ì§ê´€ì ì¸ Expression APIë¥¼ í†µí•´ ë¹ ë¥´ê³  ê°„ê²°í•˜ê²Œ ì•ŒíŒŒ ì‹œê·¸ë„ì„ ìƒì„±í•˜ê³ , í¬íŠ¸í´ë¦¬ì˜¤ ì „ëµì„ ë°±í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**í•µì‹¬ ê°€ì¹˜ ì œì•ˆ:**
- **Excel-like Expression API**: ìˆ˜ì‹ì²˜ëŸ¼ ê°„ê²°í•˜ê³  ì§ê´€ì ì¸ ì‹œê·¸ë„ ìƒì„±
- **Config-Driven Auto-Loading**: alpha-database ê¸°ë°˜ ë°ì´í„° ìë™ ë¡œë”©
- **Expression Trace**: ì‹œê·¸ë„ â†’ ê°€ì¤‘ì¹˜ â†’ ìˆ˜ìµë¥  ë³€í™” ê³¼ì • ì¶”ì 
- **Auto Universe Masking**: Field ë¡œë”©ê³¼ ê²°ê³¼ ë°˜í™˜ ì‹œ ìë™ ìœ ë‹ˆë²„ìŠ¤ í•„í„°ë§
- **Label Quantile**: Fama-French Factor ìŠ¤íƒ€ì¼ì˜ cross-sectional ê·¸ë£¹í•‘

### ë°°ê²½

ê¸°ì¡´ xarray ê¸°ë°˜ì˜ alpha-canvasëŠ” ë‹¤ì°¨ì› ë°ì´í„° ì²˜ë¦¬ì— ê°•ë ¥í•˜ì§€ë§Œ, ë¶ˆí•„ìš”í•œ ë³µì¡ì„±(xarray í•™ìŠµ ê³¡ì„ , ëª…ì‹œì  ë°ì´í„° ë“±ë¡)ìœ¼ë¡œ ì¸í•´ ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ì— ì¥ë²½ì´ ìˆì—ˆìŠµë‹ˆë‹¤. alpha-excelì€ pandas ì¤‘ì‹¬ì˜ ê°„ê²°í•œ APIë¡œ ì´ëŸ¬í•œ ë³µì¡ì„±ì„ ì œê±°í•˜ê³ , ë¦¬ì„œì²˜ê°€ Expressionì—ë§Œ ì§‘ì¤‘í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

---

## 1.2. ëŒ€ìƒ ì‚¬ìš©ì (User Persona)

**í˜ë¥´ì†Œë‚˜:** í€€íŠ¸ ë¦¬ì„œì²˜ / ë°ì´í„° ë¶„ì„ê°€

**íŠ¹ì§•:**
- Python ë° pandasì— ìµìˆ™í•¨
- ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ì„ ì›í•¨ (ìµœì†Œí•œì˜ ì„¤ì •)
- Expression ì¤‘ì‹¬ì˜ ì„ ì–¸ì  API ì„ í˜¸
- ì‹œê·¸ë„ ìƒì„±ë¶€í„° ë°±í…ŒìŠ¤íŠ¸ê¹Œì§€ ì‹ ì†í•œ iteration í•„ìš”
- Fama-French Factor ê°™ì€ í•™ìˆ ì  ì „ëµ êµ¬í˜„ í•„ìš”

---

## 1.3. í•µì‹¬ ë°ì´í„° ëª¨ë¸

### pandas DataFrame (T, N)

alpha-excelì˜ ëª¨ë“  ë°ì´í„°ëŠ” `(T, N)` (ì‹œê°„, ìì‚°) í˜•íƒœì˜ pandas DataFrameì…ë‹ˆë‹¤:
- **í–‰ (T)**: ì‹œê³„ì—´ ì¸ë±ìŠ¤ (date)
- **ì—´ (N)**: ìì‚° ì‹ë³„ì (ticker, security_id ë“±)

**ì¥ì :**
- pandas ìƒíƒœê³„ì™€ ì™„ë²½ í˜¸í™˜
- ì§ê´€ì ì¸ ë°ì´í„° ì¡°ì‘ (`.rolling()`, `.rank()` ë“±)
- ë¹ ë¥¸ ë²¡í„°í™” ì—°ì‚° ë° rolling ì—°ì‚° í˜¼í•© ê°€ëŠ¥

**ì˜ˆì‹œ:**
```python
# Returns ë°ì´í„°: (T, N) DataFrame
#           AAPL    MSFT    GOOGL
# 2024-01-02  0.01   0.02   -0.01
# 2024-01-03 -0.02   0.00    0.03
# ...
```

---

## 1.4. ì£¼ìš” ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­

### F1: Config-Driven ìë™ ë°ì´í„° ë¡œë”©

**ìš”êµ¬ì‚¬í•­:**
- Field ì°¸ì¡° ì‹œ alpha-database DataSourceì—ì„œ ìë™ìœ¼ë¡œ ë°ì´í„° ë¡œë”©
- `config/data.yaml`ì— ì •ì˜ëœ ë°ì´í„° ì†ŒìŠ¤ ì‚¬ìš©
- ëª…ì‹œì  ë°ì´í„° ë“±ë¡ ë¶ˆí•„ìš” (No `add_data()`)

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from alpha_database import DataSource
from alpha_excel import AlphaExcel, Field, TsMean

# DataSource ì´ˆê¸°í™” (config/ ë””ë ‰í† ë¦¬)
ds = DataSource('config')

# AlphaExcel ì´ˆê¸°í™”
rc = AlphaExcel(
    data_source=ds,
    start_date='2024-01-01',
    end_date='2024-12-31'
)

# Expression ì •ì˜ë§Œìœ¼ë¡œ ë°ì´í„° ìë™ ë¡œë”©
expr = TsMean(Field('returns'), window=5)
result = rc.evaluate(expr)  # 'returns' ìë™ ë¡œë”©
```

**í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜:**
- Visitor íŒ¨í„´: Expression ìˆœíšŒ ì‹œ Field ë…¸ë“œ ê°ì§€
- Lazy Loading: Field ìµœì´ˆ ì°¸ì¡° ì‹œ DataSource.load() í˜¸ì¶œ
- Caching: ë™ì¼ Field ì¬ì‚¬ìš© ì‹œ ìºì‹œì—ì„œ ë¡œë”©

---

### F2: Excel-like Expression API

**ìš”êµ¬ì‚¬í•­:**
- ìˆ˜ì‹ì²˜ëŸ¼ ì§ê´€ì í•œ Expression ì¡°í•©
- Nested Expression ì§€ì› (TsMean, Rank, Add, Subtract ë“±)
- pandas method ê¸°ë°˜ êµ¬í˜„ (vectorized + rolling í˜¼í•©)

**ì§€ì› ì—°ì‚°:**
- **Time-series**: `TsMean`, `TsStd`, `TsRank`, `TsDelta`
- **Cross-sectional**: `Rank`, `Demean`, `Neutralize`
- **Arithmetic**: `Add`, `Subtract`, `Multiply`, `Divide`
- **Logical**: `Greater`, `Less`, `Equal`

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from alpha_excel import Field, TsMean, Rank, Subtract

# 5ì¼ ì´ë™í‰ê·  ëª¨ë©˜í…€ ì‹œê·¸ë„
ma5 = TsMean(Field('returns'), window=5)
ma20 = TsMean(Field('returns'), window=20)
momentum = Subtract(ma5, ma20)

# Cross-sectional ìˆœìœ„í™”
signal = Rank(momentum)

# í‰ê°€
result = rc.evaluate(signal)
```

**êµ¬í˜„ ì›ì¹™:**
- pandas method ìš°ì„  ì‚¬ìš© (`.rolling()`, `.rank()` ë“±)
- Vectorized ì—°ì‚°ê³¼ rolling ì—°ì‚° í˜¼í•© ê°€ëŠ¥
- Universe masking ìë™ ì ìš©

---

### F3: Expression Trace (ì‹ í˜¸ â†’ ê°€ì¤‘ì¹˜ â†’ ìˆ˜ìµë¥ )

**ìš”êµ¬ì‚¬í•­:**
- Expression í‰ê°€ ê³¼ì •ì˜ ê° ë‹¨ê³„ë¥¼ ì¶”ì 
- Triple-Cache ì•„í‚¤í…ì²˜:
  - **Signal Cache**: ëª¨ë“  ì¤‘ê°„ ì‹œê·¸ë„ ì €ì¥ (ì˜ì†ì )
  - **Weight Cache**: Scaler ì ìš© í›„ í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¤‘ì¹˜ (ê°±ì‹  ê°€ëŠ¥)
  - **Portfolio Return Cache**: ê°€ì¤‘ì¹˜ ê¸°ë°˜ í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  (ê°±ì‹  ê°€ëŠ¥)

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from alpha_excel.portfolio import DollarNeutralScaler

# Expression ì •ì˜
expr = Rank(TsMean(Field('returns'), window=5))

# Scalerì™€ í•¨ê»˜ í‰ê°€ (ìë™ ë°±í…ŒìŠ¤íŠ¸)
result = rc.evaluate(expr, scaler=DollarNeutralScaler())

# ë‹¨ê³„ë³„ ì¶”ì 
for step in range(len(rc._evaluator._signal_cache)):
    name, signal = rc.get_signal(step)          # ì‹œê·¸ë„
    name, weights = rc.get_weights(step)        # ê°€ì¤‘ì¹˜
    name, port_return = rc.get_port_return(step)  # ìˆ˜ìµë¥ 

    if weights is not None:
        sharpe = calculate_sharpe(port_return)
        print(f"Step {step} ({name}): Sharpe = {sharpe:.2f}")
```

**í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜:**
- Scaler ë³€ê²½ ì‹œ Signal CacheëŠ” ì¬ì‚¬ìš©, Weight/Returnë§Œ ì¬ê³„ì‚°
- ë‹¤ì–‘í•œ ì „ëµ ë¹ ë¥´ê²Œ ë¹„êµ ê°€ëŠ¥ (ë™ì¼ ì‹œê·¸ë„, ë‹¤ë¥¸ ìŠ¤ì¼€ì¼ë§)

---

### F4: Auto Universe Masking

**ìš”êµ¬ì‚¬í•­:**
- Field ë¡œë”© ì‹œ ìë™ìœ¼ë¡œ universe mask ì ìš©
- Expression output ë°˜í™˜ ì‹œ ìë™ìœ¼ë¡œ universe mask ì ìš©
- ì´ˆê¸°í™” ì‹œ í•œ ë²ˆ ì„¤ì •, ëª¨ë“  ì—°ì‚°ì— ìë™ ë°˜ì˜

**ì§€ì› í˜•ì‹:**
- `pd.DataFrame`: Boolean mask (T, N) ì§ì ‘ ì œê³µ
- `None`: Returnsì—ì„œ ìë™ íŒŒìƒ (`~returns.isna()`)

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
# ì˜ˆì‹œ 1: ìë™ ìœ ë‹ˆë²„ìŠ¤ (returns ê¸°ë°˜)
rc = AlphaExcel(ds, start_date='2024-01-01', end_date='2024-12-31')
# universe = ~returns.isna()

# ì˜ˆì‹œ 2: ì»¤ìŠ¤í…€ ìœ ë‹ˆë²„ìŠ¤ (ê°€ê²©/ê±°ë˜ëŸ‰ í•„í„°)
price = Field('close')
volume = Field('volume')
universe_mask = (price > 5.0) & (volume > 100000)
rc = AlphaExcel(ds, start_date='2024-01-01', universe=universe_mask)

# ëª¨ë“  ì—°ì‚° ìë™ ë§ˆìŠ¤í‚¹
expr = Rank(TsMean(Field('returns'), 5))
result = rc.evaluate(expr)  # universe ì™¸ ì˜ì—­ì€ NaN
```

**í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜:**
- Field ë¡œë”© ì‹œ: `data.where(universe, np.nan)`
- Expression ì¶œë ¥ ì‹œ: `output.where(universe, np.nan)`
- Cross-sectional ì—°ì‚° (Rank, Demean)ì€ universe ë‚´ì—ì„œë§Œ ìˆ˜í–‰

---

### F5: Label Quantile (Fama-French Factor)

**ìš”êµ¬ì‚¬í•­:**
- Cross-sectional quantile ê¸°ë°˜ ê·¸ë£¹ ë¼ë²¨ë§
- Fama-French Factor ìŠ¤íƒ€ì¼ì˜ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ì§€ì›
- On-the-fly group assignment (ë™ì  ê·¸ë£¹í•‘)

**ì‚¬ìš© ì˜ˆì‹œ:**

```python
from alpha_excel import Field, LabelQuantile

# Size factor: Market Equityë¥¼ [Small, Big] 2ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¥˜
size_labels = LabelQuantile(
    Field('market_equity'),
    q=2,
    labels=['Small', 'Big']
)

# Value factor: BE/MEë¥¼ [Low, Medium, High] 3ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¥˜
value_labels = LabelQuantile(
    Field('be_me'),
    q=3,
    labels=['Low', 'Medium', 'High']
)

# 2x3 í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± (Small-High, Big-Low ë“±)
# ê° (date, ticker)ì— ëŒ€í•´ ê·¸ë£¹ ë¼ë²¨ í• ë‹¹
size_groups = rc.evaluate(size_labels)    # (T, N) DataFrame of ['Small', 'Big']
value_groups = rc.evaluate(value_labels)  # (T, N) DataFrame of ['Low', 'Medium', 'High']

# íŠ¹ì • ê·¸ë£¹ í•„í„°ë§ (ì˜ˆ: Small-High í¬íŠ¸í´ë¦¬ì˜¤)
small_high_mask = (size_groups == 'Small') & (value_groups == 'High')
```

**ê¸°ëŠ¥ ì„¸ë¶€ì‚¬í•­:**
- **Input**: Continuous characteristics (market_equity, be_me ë“±)
- **Output**: Categorical labels (T, N) DataFrame
  ```
  #           AAPL    MSFT    GOOGL
  # 2024-01-02  "Big"   "Small"  "Big"
  # 2024-01-03  "Big"   "Small"  "Small"
  ```
- **Cross-sectional**: ë§¤ ì‹œì ë§ˆë‹¤ ë…ë¦½ì ìœ¼ë¡œ quantile ê³„ì‚°
- **Universe aware**: Universe mask ë‚´ì—ì„œë§Œ quantile ê³„ì‚°

**êµ¬í˜„ ë°©ì‹:**
```python
class LabelQuantile(Expression):
    def __init__(self, child: Expression, q: int, labels: List[str]):
        self.child = child
        self.q = q
        self.labels = labels

    def accept(self, visitor):
        # pandas qcutì„ cross-sectional ì ìš©
        # data.apply(lambda row: pd.qcut(row, q=self.q, labels=self.labels, duplicates='drop'), axis=1)
        pass
```

**í™œìš© ì‚¬ë¡€:**
```python
# Fama-French SMB (Small Minus Big) Factor
size_labels = LabelQuantile(Field('market_equity'), q=2, labels=['Small', 'Big'])
size_groups = rc.evaluate(size_labels)

# Small í¬íŠ¸í´ë¦¬ì˜¤ì™€ Big í¬íŠ¸í´ë¦¬ì˜¤ì˜ ìˆ˜ìµë¥  ì°¨ì´
returns = Field('returns')
small_returns = returns.where(size_groups == 'Small').mean(axis=1)
big_returns = returns.where(size_groups == 'Big').mean(axis=1)
smb_factor = small_returns - big_returns
```

---

### F6: ê°€ì¤‘ì¹˜ ìŠ¤ì¼€ì¼ë§ ë° ë°±í…ŒìŠ¤íŠ¸

**ìš”êµ¬ì‚¬í•­:**
- ë‹¤ì–‘í•œ í¬íŠ¸í´ë¦¬ì˜¤ ìŠ¤ì¼€ì¼ë§ ì „ëµ ì§€ì›
- Forward-bias ë°©ì§€ (shift-mask workflow)
- Position-level returns ìœ ì§€ ë° on-demand ì§‘ê³„

**Scaler ì „ëµ:**
- `DollarNeutralScaler`: Long=1.0, Short=-1.0
- `GrossNetScaler`: ì»¤ìŠ¤í…€ gross/net exposure
- `LongOnlyScaler`: Long-only ì „ëµ

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from alpha_excel.portfolio import DollarNeutralScaler

# ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
expr = Rank(TsMean(Field('returns'), 5))
result = rc.evaluate(expr, scaler=DollarNeutralScaler())

# Position-level returns (T, N)
port_return = rc.get_port_return(step=-1)  # ë§ˆì§€ë§‰ ë‹¨ê³„

# Daily PnL (T,)
daily_pnl = rc.get_daily_pnl(step=-1)

# Cumulative PnL (T,)
cum_pnl = rc.get_cumulative_pnl(step=-1)

# Sharpe Ratio
sharpe = daily_pnl.mean() / daily_pnl.std() * np.sqrt(252)
```

**ë°±í…ŒìŠ¤íŠ¸ ë©”ì»¤ë‹ˆì¦˜:**
1. **Signal â†’ Weights**: Scaler.scale(signal) â†’ ê°€ì¤‘ì¹˜ ì •ê·œí™”
2. **Forward Shift**: weights.shift(1) â†’ ë‹¤ìŒë‚  í¬ì§€ì…˜
3. **Universe Mask**: weights.where(universe, 0) â†’ ìœ íš¨ í¬ì§€ì…˜ë§Œ
4. **Returns**: weights * returns â†’ position-level returns
5. **Aggregation**: .sum(axis=1) â†’ daily PnL

---

### F7: Serialization

**ìš”êµ¬ì‚¬í•­:**
- Expression ì €ì¥ ë° ë³µì›
- ë°ì´í„° ì˜ì¡´ì„± ì¶”ì¶œ

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
# Expression ì •ì˜
expr = Rank(TsMean(Field('returns'), 5))

# Serialization
expr_dict = expr.to_dict()
# {'type': 'Rank', 'child': {'type': 'TsMean', 'child': {'type': 'Field', 'name': 'returns'}, 'window': 5}}

# Deserialization
expr_loaded = Expression.from_dict(expr_dict)

# ì˜ì¡´ì„± ì¶”ì¶œ
deps = expr.get_field_dependencies()  # ['returns']
```

---

## 1.5. ì‚¬ìš©ì ì›Œí¬í”Œë¡œìš°

### ì›Œí¬í”Œë¡œìš° 1: ê¸°ë³¸ ì‹œê·¸ë„ ìƒì„±

```mermaid
flowchart TD
    Start(["ë¦¬ì„œì²˜ ì‹œì‘"]) --> Init["AlphaExcel ì´ˆê¸°í™”<br/>DataSource, ë‚ ì§œ ì„¤ì •"]
    Init --> Define["Expression ì •ì˜<br/>TsMean, Rank ë“±"]
    Define --> Eval["rc.evaluate í˜¸ì¶œ<br/>ìë™ ë°ì´í„° ë¡œë”©"]
    Eval --> Analyze["ê²°ê³¼ ë¶„ì„<br/>DataFrame í™•ì¸"]
    Analyze --> Decision{"ë§Œì¡±?"}
    Decision -->|"No"| Modify["Expression ìˆ˜ì •"]
    Modify --> Eval
    Decision -->|"Yes"| Export["ê²°ê³¼ ë‚´ë³´ë‚´ê¸°"]
    Export --> End(["ì™„ë£Œ"])
```

### ì›Œí¬í”Œë¡œìš° 2: ë°±í…ŒìŠ¤íŠ¸ ë° ì „ëµ ë¹„êµ

```mermaid
flowchart TD
    Start(["Expression ì •ì˜"]) --> First["ì²« ë²ˆì§¸ scalerë¡œ í‰ê°€"]
    First --> Cache["Signal Cache ì €ì¥"]
    Cache --> Compare["ë‹¤ë¥¸ scalerë¡œ ì¬í‰ê°€"]
    Compare --> Reuse["Signal ì¬ì‚¬ìš©<br/>Weightë§Œ ì¬ê³„ì‚°"]
    Reuse --> Analysis["ì„±ê³¼ ë¹„êµ<br/>Sharpe, PnL"]
    Analysis --> Decision{"ìµœì  ì „ëµ?"}
    Decision -->|"No"| Compare
    Decision -->|"Yes"| End(["ì™„ë£Œ"])
```

### ì›Œí¬í”Œë¡œìš° 3: Fama-French Factor êµ¬ì„±

```mermaid
flowchart TD
    Start(["Factor ì—°êµ¬"]) --> Size["Size label ì •ì˜<br/>LabelQuantile(market_equity, 2)"]
    Size --> Value["Value label ì •ì˜<br/>LabelQuantile(be_me, 3)"]
    Value --> Groups["2x3 í¬íŠ¸í´ë¦¬ì˜¤<br/>Small-High, Big-Low ë“±"]
    Groups --> Strategy["ê° ê·¸ë£¹ë³„ ì „ëµ<br/>Long High, Short Low"]
    Strategy --> Backtest["ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"]
    Backtest --> End(["ë¶„ì„ ì™„ë£Œ"])
```

---

## 1.6. êµ¬í˜„ ì›ì¹™

### pandas Method ìš°ì„  ì‚¬ìš©

**ì›ì¹™:**
- Vectorized ì—°ì‚°ê³¼ rolling ì—°ì‚° í˜¼í•©
- pandasì˜ íš¨ìœ¨ì ì¸ built-in method í™œìš©
- ì»¤ìŠ¤í…€ êµ¬í˜„ì€ ìµœì†Œí™”

**ì˜ˆì‹œ:**
```python
# TsMean: pandas rolling mean
def ts_mean(data: pd.DataFrame, window: int) -> pd.DataFrame:
    return data.rolling(window=window).mean()

# Rank: pandas rank
def rank(data: pd.DataFrame) -> pd.DataFrame:
    return data.rank(axis=1, pct=True)

# Demean: pandas cross-sectional mean subtraction
def demean(data: pd.DataFrame) -> pd.DataFrame:
    return data.sub(data.mean(axis=1), axis=0)
```

### Visitor Pattern

**ì›ì¹™:**
- Expression ìˆœíšŒ ì‹œ ê° ë…¸ë“œ ë°©ë¬¸
- Field ë…¸ë“œì—ì„œ ë°ì´í„° ìë™ ë¡œë”©
- ì—°ì‚° ë…¸ë“œì—ì„œ ê²°ê³¼ ê³„ì‚° ë° ìºì‹±

**êµ¬í˜„:**
```python
class Evaluator:
    def visit_Field(self, field: Field) -> pd.DataFrame:
        # DataSourceì—ì„œ ìë™ ë¡œë”©
        data = self.data_source.load(field.name, self.start_date, self.end_date)
        # Universe masking
        return data.where(self.universe, np.nan)

    def visit_TsMean(self, ts_mean: TsMean) -> pd.DataFrame:
        child_data = ts_mean.child.accept(self)
        result = child_data.rolling(window=ts_mean.window).mean()
        # Cache signal
        self._signal_cache.append((ts_mean.name, result))
        return result
```

---

## 1.7. MVP ë²”ìœ„

### í¬í•¨ë¨ (Implemented)

- âœ… **Config-driven auto-loading**: alpha-database DataSource ê¸°ë°˜
- âœ… **Excel-like Expression API**: TsMean, Rank, Arithmetic ë“±
- âœ… **Triple-cache architecture**: Signal, Weight, Portfolio Return
- âœ… **Auto universe masking**: Field ë¡œë”© ë° output ì‹œ ìë™ ì ìš©
- âœ… **Portfolio backtesting**: DollarNeutral, GrossNet, LongOnly Scaler
- âœ… **Serialization**: Expression to/from dict

### ì¶”ê°€ ì˜ˆì • (Planned)

- ğŸ”œ **Label Quantile**: Fama-French Factor ê·¸ë£¹í•‘
- ğŸ”œ **Group operations**: GroupNeutralize, GroupDemean (industry ë“±)
- ğŸ”œ **String universe**: 'univ100', 'univ200' ë“± ì‚¬ì „ ì •ì˜ ìœ ë‹ˆë²„ìŠ¤

### ì œì™¸ë¨ (Out of Scope)

- âŒ **Signal Canvas**: NumPy-style assignment
- âŒ **xarray ì§€ì›**: pandas only
- âŒ **ëª…ì‹œì  ë°ì´í„° ë“±ë¡**: No `add_data()`

---

## 1.8. ì„±ê³µ ì§€í‘œ

**ì •ì„±ì  ì§€í‘œ:**
- ë¦¬ì„œì²˜ê°€ 5ë¶„ ë‚´ ì²« ì‹œê·¸ë„ ìƒì„± ê°€ëŠ¥
- Expression ì½”ë“œ ë¼ì¸ ìˆ˜ 50% ê°ì†Œ
- pandasë§Œìœ¼ë¡œ ëª¨ë“  ì—°ì‚° ê°€ëŠ¥ (xarray í•™ìŠµ ë¶ˆí•„ìš”)

**ì •ëŸ‰ì  ì§€í‘œ:**
- ë°±í…ŒìŠ¤íŠ¸ ì†ë„: 10ë…„ ë°ì´í„°, 1000ê°œ ìì‚° ê¸°ì¤€ < 10ì´ˆ
- ìºì‹œ íš¨ìœ¨: Scaler ë³€ê²½ ì‹œ ì¬ê³„ì‚° ì‹œê°„ < 1ì´ˆ
- ë©”ëª¨ë¦¬ íš¨ìœ¨: Triple-cache ì‚¬ìš© ì‹œ ë©”ëª¨ë¦¬ ì¦ê°€ < 2ë°°

---
