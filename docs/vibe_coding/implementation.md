# 3. Implementation Guide

이 문서는 alpha-canvas의 구체적인 구현 방법론, 인터페이스 설계, 그리고 개발 표준을 정의합니다.

## 3.1. 프로젝트 구조

```text
alpha-canvas/
├── config/                      # 타입별 설정 파일
│   ├── data.yaml               # 데이터 필드 정의
│   ├── db.yaml                 # 데이터베이스 연결 설정 (선택적)
│   └── compute.yaml            # 계산 관련 설정 (선택적)
├── src/
│   └── alpha_canvas/
│       ├── __init__.py
│       ├── core/
│       │   ├── facade.py       # AlphaCanvas (rc) 퍼사드 클래스
│       │   ├── expression.py   # Expression 컴포짓 트리
│       │   ├── visitor.py      # EvaluateVisitor 패턴 (타입 검사 포함)
│       │   └── config.py       # ConfigLoader
│       ├── ops/                # 연산자 (ts_mean, rank, etc.)
│       │   ├── __init__.py
│       │   ├── timeseries.py   # ts_mean, ts_sum, etc. (다형성 연산자)
│       │   ├── crosssection.py # cs_rank 등 (Panel 전용 연산자)
│       │   ├── classification.py # cs_quantile, cs_cut (분류기/축 생성)
│       │   ├── transform.py    # group_neutralize, etc.
│       │   └── tensor.py       # 미래 확장용 (MVP에서는 비어있음)
│       ├── analysis/
│       │   ├── pnl.py          # PnLTracer
│       │   └── metrics.py      # 성과 지표 계산
│       └── utils/
│           ├── accessor.py     # Property 접근자 (data, axis, rules)
│           └── mask.py         # 마스크 헬퍼
├── experiments/                # 실험 스크립트
├── tests/                      # 테스트
└── docs/
    └── vibe_coding/
        ├── prd.md
        ├── architecture.md
        └── implementation.md   # 이 문서
```

## 3.2. 핵심 인터페이스 설계

### 3.2.1. 초기화 및 설정

```python
from alpha_canvas import AlphaCanvas

# config/ 디렉토리의 모든 YAML 파일을 자동 로드
rc = AlphaCanvas()

# 또는 특정 config 디렉토리 지정
rc = AlphaCanvas(config_dir='./custom_config')
```

**구현 요구사항:**
- `AlphaCanvas.__init__()` 내부에서 `ConfigLoader`를 생성하고 `config/` 디렉토리의 모든 `.yaml` 파일을 로드합니다.
- `ConfigLoader`는 `data.yaml`, `db.yaml` 등을 각각 파싱하여 내부 dict에 저장합니다.

### 3.2.2. 코어 데이터 모델 구현 (Core Data Model Implementation)

#### A. `AlphaCanvas.add_data()` 구현 (`facade.py`)

```python
def add_data(self, name: str, data: Union[Expression, xr.DataArray]) -> None:
    """데이터 변수를 Dataset에 추가 (Expression 또는 DataArray 지원)"""
    
    # Case 1: Expression 평가 (일반적인 경로)
    if isinstance(data, Expression):
        self.rules[name] = data  # Expression 저장 (재평가 가능하도록)
        result_array = self._evaluator.evaluate(data)  # Visitor로 평가
        self.db = self.db.assign({name: result_array})  # data_vars에 추가
    
    # Case 2: DataArray 직접 주입 (Open Toolkit: Inject)
    elif isinstance(data, xr.DataArray):
        # 외부에서 생성한 데이터 주입 (Visitor 건너뛰기)
        self.db = self.db.assign({name: data})
    
    else:
        raise TypeError(f"data must be Expression or DataArray, got {type(data)}")
```

**핵심 사항:**
- `xarray.Dataset.assign()`을 사용하여 Data Variable로 추가
- `Expression`과 `DataArray` 모두 지원 (오버로딩)
- Open Toolkit 철학: 외부 계산 결과를 seamlessly inject

#### B. `rc.db` 프로퍼티 (Open Toolkit: Eject)

```python
@property
def db(self) -> xr.Dataset:
    """순수 xarray.Dataset 반환 (Jupyter eject용)"""
    return self._dataset  # 내부 Dataset을 그대로 노출
```

**핵심 사항:**
- 래핑 없이 순수 `xarray.Dataset` 반환
- 사용자는 `pure_ds = rc.db`로 꺼내서 scipy/statsmodels 사용 가능

#### C. `rc.axis` Accessor 구현 (Selector Interface)

```python
class AxisAccessor:
    """rc.axis.size['small'] → (rc.db['size'] == 'small')로 변환"""
    
    def __init__(self, rc: 'AlphaCanvas'):
        self._rc = rc
    
    def __getattr__(self, axis_name: str) -> 'AxisSelector':
        if axis_name not in self._rc.db:
            raise AttributeError(f"Axis '{axis_name}' not found in rc.db")
        return AxisSelector(self._rc.db[axis_name])

class AxisSelector:
    def __init__(self, data_var: xr.DataArray):
        self._data_var = data_var
    
    def __getitem__(self, label: str) -> xr.DataArray:
        # 표준 xarray 불리언 인덱싱
        return (self._data_var == label)
```

**핵심 사항:**
- `rc.axis.size['small']`은 단순한 syntactic sugar
- 실제로는 `(rc.db['size'] == 'small')`이라는 표준 xarray 연산
- 별도의 Expression 생성 없이 즉시 Boolean mask 반환

### 3.2.3. Interface A: Formula-based (Excel-like)

```python
from alpha_canvas.ops import ts_mean, rank, group_neutralize, Field

# 1. 간단한 헬퍼 함수 스타일 (즉시 평가)
returns_10d = rc.ts_mean('returns', 10)  
# rc.db['returns_10d']에 DataArray 저장

# 2. 복잡한 Expression 정의 (지연 평가)
alpha_expr = group_neutralize(
    rank(ts_mean(Field('returns'), 10)),
    group_by='subindustry'
)

# 3. Expression을 변수로 등록
rc.add_data_var('alpha1', alpha_expr)

# 4. 데이터 접근
alpha1_data = rc.data.alpha1  # xarray.DataArray (T, N)
```

**구현 요구사항:**

- `Field('returns')`: `ConfigLoader`에서 `config/data.yaml`의 `returns` 정의를 참조하는 Leaf Expression
- `ts_mean()`, `rank()` 등: Composite Expression 노드를 생성
- `rc.add_data_var()`: Expression을 `rc.rules`에 등록하고, `EvaluateVisitor`로 평가하여 `rc.db`에 저장

### 3.2.3. Interface B: Selector-based (NumPy-like)

```python
# 1. 시그널 캔버스 초기화
rc.init_signal_canvas('my_alpha')  
# rc.db['my_alpha']에 (T, N) 영행렬 생성

# 2. 데이터 등록
rc.add_data('mcap', Field('market_cap'))
rc.add_data('ret', Field('returns'))
rc.add_data('vol', Field('volume'))

# 3. 가상 축(Axis) 정의 - 레이블 기반 버킷
rc.add_data('size', cs_quantile(rc.data.mcap, bins=3, labels=['small', 'mid', 'big']))
rc.add_data('momentum', cs_quantile(rc.data.ret, bins=2, labels=['low', 'high']))
rc.add_data('surge', ts_any(rc.data.ret > 0.3, window=252))  # Boolean

# 4. 셀렉터로 Boolean 마스크 생성
mask_long = (rc.axis.size['small'] & rc.axis.momentum['high'] & rc.axis.surge)
mask_short = (rc.axis.size['big'] & rc.axis.momentum['low'])

# 5. NumPy-style 할당
rc['my_alpha'][mask_long] = 1.0
rc['my_alpha'][mask_short] = -1.0

# 또는 현재 활성 캔버스에 직접 할당
rc[mask_long] = 1.0

# 6. 최종 시그널 접근
my_alpha = rc.data.my_alpha  # xarray.DataArray (T, N)
```

**구현 요구사항:**

- `rc.add_data('size', expr)`: Expression을 평가하고 `rc.db.assign({'size': result})`로 data_vars에 추가
- `rc.axis.size['small']`: 
  1. `AxisAccessor`가 `rc.db['size']`에 접근
  2. `AxisSelector.__getitem__('small')`이 `(rc.db['size'] == 'small')`을 반환
  3. 표준 xarray 불리언 인덱싱, Expression 생성 없음
- `rc[mask] = value`: `xr.where(mask, value, rc.db[current_canvas])`로 할당

### 3.2.4. Interface C: Selective Traceability (Integer-Based Steps)

```python
# 복잡한 Expression 정의
complex_alpha = group_neutralize(
    rank(ts_mean(Field('returns'), 5)),
    group_by='subindustry'
)

rc.add_data_var('complex_alpha', complex_alpha)

# Expression 트리 구조 (depth-first 순서):
# step 0: Field('returns')
# step 1: ts_mean(Field('returns'), 5)
# step 2: rank(...)
# step 3: group_neutralize(...)

# 1. 특정 단계만 추적
pnl_step1 = rc.trace_pnl('complex_alpha', step=1)
# {'sharpe': 0.7, 'total_pnl': 150, 'cumulative_returns': [...]}

# 2. 모든 단계 추적
pnl_all = rc.trace_pnl('complex_alpha')  # step=None (default)
# {
#   0: {'step_name': 'Field_returns', 'sharpe': 0.5, ...},
#   1: {'step_name': 'ts_mean', 'sharpe': 0.7, ...},
#   2: {'step_name': 'rank', 'sharpe': 0.6, ...},
#   3: {'step_name': 'group_neutralize', 'sharpe': 0.8, ...}
# }

# 3. 중간 데이터 직접 접근
intermediate = rc.get_intermediate('complex_alpha', step=1)
# xarray.DataArray (T, N) - ts_mean 적용 후 데이터

# 4. 복잡한 Expression 예시 (병렬 연산)
combo_alpha = ts_mean(Field('returns'), 3) + rank(Field('market_cap'))
rc.add_data_var('combo', combo_alpha)

# step 0: Field('returns')
# step 1: ts_mean(Field('returns'), 3)
# step 2: Field('market_cap')
# step 3: rank(Field('market_cap'))
# step 4: add(step1, step3)

pnl_step4 = rc.trace_pnl('combo', step=4)  # 최종 결과
```

**구현 요구사항:**

- `EvaluateVisitor.cache` 구조: `dict[str, dict[int, tuple[str, xr.DataArray]]]`
  - 외부 키: 변수명 (e.g., `'complex_alpha'`)
  - 내부 키: 정수 step 인덱스 (0부터 시작)
  - 값: `(노드_이름, DataArray)` 튜플 (디버깅용 메타데이터 포함)
- `EvaluateVisitor._step_counter`: 현재 step 인덱스를 추적하는 내부 카운터
- `EvaluateVisitor`는 Expression 트리를 **깊이 우선 탐색(depth-first)** 으로 순회하며 각 노드의 반환값을 캐시에 저장
- `rc.trace_pnl(var, step=None)`:
  - `step=None`: 모든 단계의 캐시 데이터를 `PnLTracer`에 전달
  - `step=1`: 해당 단계만 전달
- `rc.get_intermediate(var, step)`: `rc._evaluator.cache[var][step][1]` 반환 (DataArray 부분)

### 3.2.5. 핵심 활용 패턴: 팩터 수익률 계산

#### A. 독립 이중 정렬 (Independent Double Sort) - Fama-French SMB

```python
from alpha_canvas.ops import cs_quantile, Field

# 1. 데이터 등록
rc.add_data('mcap', Field('market_cap'))
rc.add_data('btm', Field('book_to_market'))

# 2. 독립 정렬: 전체 유니버스에서 각각 quantile 계산
rc.add_axis('size', cs_quantile(rc.data.mcap, bins=2, labels=['small', 'big']))
rc.add_axis('value', cs_quantile(rc.data.btm, bins=3, labels=['low', 'mid', 'high']))

# 3. SMB 포트폴리오 구성
rc.init_signal_canvas('smb')
rc[rc.axis.size['small']] = 1.0   # Long all small stocks
rc[rc.axis.size['big']] = -1.0    # Short all big stocks

# 4. 팩터 수익률 추적
smb_returns = rc.trace_pnl('smb')
print(f"SMB Sharpe: {smb_returns['sharpe']:.2f}")
```

#### B. 종속 이중 정렬 (Dependent Double Sort) - Fama-French HML

```python
# 1. 첫 번째 정렬: Size
rc.add_axis('size', cs_quantile(rc.data.mcap, bins=2, labels=['small', 'big']))

# 2. 종속 정렬: 각 Size 그룹 내에서 Value quantile 계산
rc.add_axis('value', cs_quantile(rc.data.btm, bins=3, labels=['low', 'mid', 'high'],
                                   group_by='size'))
# group_by='size'는 rc.rules['size']를 참조하여
# 'small' 그룹과 'big' 그룹 내에서 각각 독립적으로 quantile을 계산

# 3. HML 포트폴리오 구성 (각 Size 그룹 내에서 High-Low)
rc.init_signal_canvas('hml')
rc[rc.axis.value['high']] = 1.0   # Long high B/M (value) in both size groups
rc[rc.axis.value['low']] = -1.0   # Short low B/M (growth) in both size groups

# 4. 팩터 수익률 추적
hml_returns = rc.trace_pnl('hml')
print(f"HML Sharpe: {hml_returns['sharpe']:.2f}")
```

#### C. 로우레벨 마스크 활용 (Advanced Custom Logic)

```python
# 유동성 필터링된 유니버스에서 모멘텀 팩터 구성
rc.add_data('volume', Field('volume'))
rc.add_data('returns', Field('returns'))

# 1. 고유동성 마스크 생성
high_liquidity = rc.data.volume > rc.data.volume.quantile(0.5)

# 2. 마스크 적용된 quantile 계산
rc.add_axis('momentum', cs_quantile(rc.data.returns, bins=5, labels=['q1','q2','q3','q4','q5'],
                                      mask=high_liquidity))
# mask=False인 종목은 NaN으로 처리됨

# 3. 롱-숏 포트폴리오
rc.init_signal_canvas('momentum_factor')
rc[rc.axis.momentum['q5']] = 1.0
rc[rc.axis.momentum['q1']] = -1.0

mom_returns = rc.trace_pnl('momentum_factor')
```

#### D. 다차원 팩터 조합 (Multi-Factor Strategy)

```python
# 독립 정렬로 3개 팩터 축 생성
rc.add_axis('size', cs_quantile(rc.data.mcap, bins=3, labels=['small','mid','big']))
rc.add_axis('momentum', cs_quantile(rc.data.mom, bins=5, labels=['q1','q2','q3','q4','q5']))
rc.add_axis('quality', cs_quantile(rc.data.roe, bins=3, labels=['low','mid','high']))

# 복잡한 다차원 선택
rc.init_signal_canvas('multi_factor')

# Small & High Momentum & High Quality
long_mask = (rc.axis.size['small'] & 
             rc.axis.momentum['q5'] & 
             rc.axis.quality['high'])

# Big & Low Momentum & Low Quality
short_mask = (rc.axis.size['big'] & 
              rc.axis.momentum['q1'] & 
              rc.axis.quality['low'])

rc[long_mask] = 1.0
rc[short_mask] = -1.0

multi_returns = rc.trace_pnl('multi_factor')
```

**설계 의도:**

- 이 패턴들이 alpha-canvas의 **핵심 활용 사례**입니다.
- **Fama-French 재현**: `group_by`로 종속 정렬을 간결하게 표현
- **유연성**: `mask`로 커스텀 유니버스 필터링 가능
- 듀얼 인터페이스(Formula + Selector)의 조합으로 복잡한 다차원 팩터 포트폴리오를 간결하게 표현합니다.
- 레이블 기반 선택(`'small'`, `'q5'`, `'high'`)으로 가독성과 유지보수성을 확보합니다.

## 3.3. 연산자 구현 패턴 (Operator Implementation Pattern)

### 3.3.1. 책임 분리 원칙

**핵심 원칙:** 연산자는 자신의 계산 로직을 소유하고, Visitor는 순회 및 캐싱만 담당합니다.

**잘못된 패턴 (Anti-Pattern):**
```python
# ❌ BAD: Visitor가 계산 로직을 포함
class EvaluateVisitor:
    def visit_ts_mean(self, node):
        child_result = node.child.accept(self)
        # Visitor 안에 rolling 계산 로직이 들어감 (잘못됨!)
        result = child_result.rolling(time=node.window, min_periods=node.window).mean()
        self._cache_result("TsMean", result)
        return result
```

**올바른 패턴 (Correct Pattern):**
```python
# ✅ GOOD: 연산자가 계산 로직을 소유
@dataclass
class TsMean(Expression):
    child: Expression
    window: int
    
    def accept(self, visitor):
        """Visitor 인터페이스: 순회를 위한 진입점"""
        return visitor.visit_ts_mean(self)
    
    def compute(self, child_result: xr.DataArray) -> xr.DataArray:
        """핵심 계산 로직: 연산자가 소유"""
        return child_result.rolling(
            time=self.window,
            min_periods=self.window
        ).mean()

# ✅ GOOD: Visitor는 순회 및 캐싱만 담당
class EvaluateVisitor:
    def visit_ts_mean(self, node: TsMean) -> xr.DataArray:
        """트리 순회 및 상태 수집"""
        # 1. 순회: 자식 노드 평가
        child_result = node.child.accept(self)
        
        # 2. 계산 위임: 연산자에게 맡김
        result = node.compute(child_result)
        
        # 3. 상태 수집: 결과 캐싱
        self._cache_result("TsMean", result)
        
        return result
```

### 3.3.2. 연산자 구현 체크리스트

모든 연산자는 다음 구조를 따라야 합니다:

```python
@dataclass
class OperatorName(Expression):
    """연산자 설명.
    
    Args:
        child: 자식 Expression (필요시)
        param1: 연산자 파라미터 1
        param2: 연산자 파라미터 2
    
    Returns:
        연산 결과 DataArray
    """
    child: Expression  # 자식 노드 (있는 경우)
    param1: type1      # 연산자 파라미터들
    param2: type2
    
    def accept(self, visitor) -> xr.DataArray:
        """Visitor 인터페이스."""
        return visitor.visit_operator_name(self)
    
    def compute(self, *inputs: xr.DataArray) -> xr.DataArray:
        """핵심 계산 로직.
        
        Args:
            *inputs: 자식 노드들의 평가 결과
        
        Returns:
            이 연산의 결과 DataArray
        
        Note:
            이 메서드는 순수 함수여야 합니다 (부작용 없음).
            Visitor 참조 없이 독립적으로 테스트 가능해야 합니다.
        """
        # 실제 계산 로직
        result = ...  # xarray/numpy 연산
        return result
```

**체크리스트:**
- [ ] `accept()` 메서드: Visitor 인터페이스 제공
- [ ] `compute()` 메서드: 핵심 계산 로직 캡슐화
- [ ] `compute()`는 순수 함수 (부작용 없음)
- [ ] `compute()`는 Visitor 독립적 (직접 테스트 가능)
- [ ] Docstring으로 Args/Returns 명확히 문서화

### 3.3.3. Visitor 구현 패턴

모든 `visit_*()` 메서드는 동일한 3단계 패턴을 따릅니다:

```python
def visit_operator_name(self, node: OperatorName) -> xr.DataArray:
    """연산자 노드 방문: 순회 및 캐싱.
    
    Args:
        node: 연산자 Expression 노드
    
    Returns:
        연산 결과 DataArray
    """
    # 1️⃣ 순회(Traversal): 자식 노드들 평가
    child_result_1 = node.child1.accept(self)  # 깊이 우선
    child_result_2 = node.child2.accept(self)  # (있는 경우)
    
    # 2️⃣ 계산 위임(Delegation): 연산자에게 맡김
    result = node.compute(child_result_1, child_result_2)
    
    # 3️⃣ 상태 수집(State Collection): 결과 캐싱
    self._cache_result("OperatorName", result)
    
    return result
```

**Visitor의 역할:**
- ✅ **트리 순회:** 깊이 우선으로 자식 노드 방문
- ✅ **계산 위임:** `node.compute()`로 계산 맡김
- ✅ **상태 수집:** 중간 결과를 정수 스텝으로 캐싱
- ❌ **계산 로직 포함 금지:** rolling, rank, quantile 등의 로직은 연산자에 속함

### 3.3.4. 테스트 전략

**1. 연산자 단위 테스트 (Operator Unit Tests):**

```python
def test_ts_mean_compute_directly():
    """TsMean.compute() 메서드를 직접 테스트 (Visitor 없이)."""
    # 입력 데이터 준비
    data = xr.DataArray(
        [[1, 2], [3, 4], [5, 6]],
        dims=['time', 'asset']
    )
    
    # 연산자 생성
    operator = TsMean(child=Field('dummy'), window=2)
    
    # compute() 직접 호출 (Visitor 우회)
    result = operator.compute(data)
    
    # 검증
    assert np.isnan(result.values[0, 0])  # 첫 행 NaN
    assert result.values[1, 0] == 2.0     # mean([1, 3])
```

**2. 통합 테스트 (Integration Tests):**

```python
def test_ts_mean_with_visitor():
    """TsMean이 Visitor와 통합되어 작동하는지 테스트."""
    ds = xr.Dataset({'returns': data})
    visitor = EvaluateVisitor(ds)
    
    expr = TsMean(child=Field('returns'), window=3)
    result = visitor.evaluate(expr)
    
    # 캐싱 검증
    assert len(visitor._cache) == 2  # Field + TsMean
```

### 3.3.5. 이점 요약

| 측면 | 잘못된 패턴 | 올바른 패턴 |
|------|-------------|-------------|
| **책임** | Visitor가 모든 계산 담당 | 연산자가 자신의 계산 소유 |
| **테스트** | Visitor를 통해서만 테스트 | `compute()` 직접 테스트 가능 |
| **유지보수** | Visitor가 비대해짐 | 각 연산자 독립적 |
| **확장성** | 새 연산자마다 Visitor 수정 | Visitor 수정 최소화 |
| **단일 책임** | Visitor가 다중 책임 | 각 클래스 단일 책임 |

---

## 3.4. Cross-Sectional Quantile 연산자 구현

### 3.3.1. `cs_quantile` Expression 클래스

```python
from dataclasses import dataclass
from typing import Optional, List, Union

@dataclass
class CsQuantile(Expression):
    """Cross-sectional quantile bucketing with optional grouping or masking."""
    
    data: Expression  # 버킷화할 데이터 (e.g., Field('market_cap'))
    bins: int  # 버킷 개수
    labels: List[str]  # 레이블 리스트 (길이 = bins)
    group_by: Optional[str] = None  # 종속 정렬용: axis 이름 (string), pandas.groupby처럼
    mask: Optional[Expression] = None  # 로우레벨 필터링용: Boolean Expression
    
    def accept(self, visitor: Visitor):
        return visitor.visit_cs_quantile(self)
```

### 3.3.2. `EvaluateVisitor.visit_cs_quantile` 구현

```python
def visit_cs_quantile(self, node: CsQuantile) -> xr.DataArray:
    """
    cs_quantile 평가: 독립/종속 정렬 및 마스크 지원.
    
    중요: 종속 정렬은 xarray.groupby().apply()의 표준 패턴을 사용합니다.
    """
    
    # 1. 데이터 평가 및 타입 검사 (MVP: DataPanel만 허용)
    data = node.data.accept(self)  # (T, N) DataArray
    if not self._is_data_panel(data):
        raise TypeError(f"cs_quantile requires DataPanel, got {type(data)}")
    
    # 2. 마스크 처리 (옵션)
    if node.mask is not None:
        mask = node.mask.accept(self)  # (T, N) Boolean
        data = data.where(mask, np.nan)  # mask=False인 곳은 NaN
    
    # 3-A. 독립 정렬 (group_by=None)
    if node.group_by is None:
        return self._quantile_independent(data, node.bins, node.labels)
    
    # 3-B. 종속 정렬 (group_by 지정 - xarray.groupby 활용)
    else:
        # group_by는 문자열 (axis 이름)
        group_labels = self._rc.db[node.group_by]  # rc.db에서 직접 조회
        return self._quantile_grouped(data, group_labels, node.bins, node.labels)

def _quantile_independent(self, data: xr.DataArray, bins: int, labels: List[str]) -> xr.DataArray:
    """전체 유니버스에서 quantile 계산."""
    # xarray의 quantile 기능 활용하여 각 time step별로 cross-sectional quantile 계산
    # pd.qcut 스타일로 bins 개로 분할하고 labels 할당
    # 반환: (T, N) Categorical DataArray
    ...

def _quantile_grouped(self, data: xr.DataArray, groups: xr.DataArray, 
                      bins: int, labels: List[str]) -> xr.DataArray:
    """
    각 그룹 내에서 독립적으로 quantile 계산 (xarray.groupby 활용).
    
    이것이 xarray.groupby().apply()의 표준 사용 패턴입니다.
    """
    
    def quantile_function(group_data: xr.DataArray) -> xr.DataArray:
        """각 그룹에 적용할 quantile 함수"""
        # group_data는 해당 그룹('small' 또는 'big')에 속하는 데이터만 포함
        return self._quantile_independent(group_data, bins, labels)
    
    # xarray.groupby().apply() - 표준 패턴
    result = data.groupby(groups).apply(quantile_function)
    
    return result
```

**핵심 구현 사항:**

1. **타입 검사:** MVP에서는 `DataPanel` 타입만 허용 (`_is_data_panel()` 헬퍼 사용)
2. **독립 정렬:** 전체 유니버스 대상 quantile 계산
3. **종속 정렬:** `xarray.groupby().apply(quantile_function)` 사용
   - `group_by`는 문자열로 받아 `rc.db[group_by]`에서 레이블 조회
   - `.apply()`에 커스텀 quantile 함수 전달
   - xarray가 자동으로 그룹별 결과를 병합
4. **마스크:** `data.where(mask, np.nan)`로 필터링

### 3.3.3. 사용 예시 비교

```python
# 독립 정렬: 간단한 Expression
size_expr = CsQuantile(
    data=Field('market_cap'),
    bins=2,
    labels=['small', 'big']
)

# 종속 정렬: group_by로 기존 axis 참조
value_expr = CsQuantile(
    data=Field('book_to_market'),
    bins=3,
    labels=['low', 'mid', 'high'],
    group_by='size'  # 'size' axis의 결과를 먼저 평가 → 각 그룹별 quantile
)

# 마스크 적용: Boolean Expression
momentum_expr = CsQuantile(
    data=Field('returns'),
    bins=5,
    labels=['q1', 'q2', 'q3', 'q4', 'q5'],
    mask=GreaterThan(Field('volume'), Quantile(Field('volume'), 0.5))
)
```

## 3.4. Property Accessor 구현

```python
# rc.data: DataAccessor
class DataAccessor:
    def __init__(self, db: xr.Dataset):
        self._db = db
    
    def __getattr__(self, name: str) -> xr.DataArray:
        if name in self._db:
            return self._db[name]
        raise AttributeError(f"Data '{name}' not found")

# rc.axis: AxisAccessor
class AxisAccessor:
    def __init__(self, rc: 'AlphaCanvas'):
        self._rc = rc
    
    def __getattr__(self, axis_name: str) -> 'AxisSelector':
        if axis_name not in self._rc.rules:
            raise AttributeError(f"Axis '{axis_name}' not defined")
        return AxisSelector(self._rc, axis_name)

class AxisSelector:
    def __getitem__(self, label: str) -> xr.DataArray:
        # rc.rules에서 Expression 조회 → Equals(..., label) 생성 → 평가
        ...
```

## 3.5. 개발 원칙

### 3.5.1. 지연 평가 (Lazy Evaluation)

- `Expression` 객체는 "레시피"이며 데이터를 가지지 않습니다.
- `EvaluateVisitor`가 실제 평가를 담당하며, 이때 캐싱이 발생합니다.
- 불필요한 재계산을 방지하여 성능을 최적화합니다.

### 3.5.2. 레이블 우선 (Label-first)

- 모든 버킷 연산은 정수 인덱스 대신 **의미 있는 레이블**을 반환해야 합니다.
- 예: `cs_quantile(..., labels=['small', 'mid', 'big'])`
- 이는 PRD의 핵심 문제 2를 해결하는 설계 원칙입니다.

### 3.5.3. 추적성 우선 (Traceability-first)

- 모든 중간 계산 결과는 **정수 step 인덱스**로 캐시되어야 합니다.
- 사용자는 재계산 없이 모든 중간 단계를 검사할 수 있어야 합니다.
- 이는 PRD의 핵심 문제 3을 해결하는 설계 원칙입니다.

### 3.5.4. Pythonic 우선 (Pythonic-first)

- 문자열 DSL 대신 Python의 네이티브 문법을 활용합니다.
- 예: `&`, `|`, `[]`, `=` 연산자 오버로딩
- IDE 자동완성 및 타입 힌트를 최대한 활용합니다.

### 3.5.5. 종속 정렬 지원 (Dependent Sort Support)

- `cs_quantile`은 `group_by` 파라미터로 종속 정렬을 지원해야 합니다.
- 이는 Fama-French 팩터 재현을 위한 핵심 요구사항입니다.
- `mask` 파라미터로 로우레벨 커스터마이징도 가능해야 합니다.

## 3.6. 테스트 전략

### 3.6.1. 단위 테스트

- `Expression` 각 노드 클래스
- `EvaluateVisitor` 메서드별 테스트 (특히 `visit_cs_quantile`의 `group_by` 로직)
- `ConfigLoader` YAML 파싱 테스트
- 정수 step 인덱싱 로직

### 3.6.2. 통합 테스트

- 전체 워크플로우 (초기화 → 데이터 로드 → Expression 평가 → PnL 추적)
- 듀얼 인터페이스 조합 시나리오
- 독립/종속 이중 정렬 기반 팩터 수익률 계산 패턴
- Fama-French SMB, HML 팩터 재현 검증

### 3.6.3. 성능 테스트

- 대용량 데이터 (T=1000, N=3000) 처리 시간
- 캐싱 효과 검증 (step별 조회 성능)
- 종속 정렬의 오버헤드 측정
- 메모리 사용량 프로파일링

## 3.7. 코딩 컨벤션

- **타입 힌트:** 모든 public 메서드에 타입 힌트 필수
- **Docstring:** Google 스타일 docstring 사용
- **Linting:** `ruff` 사용
- **Formatting:** `black` 사용
- **Import 순서:** 표준 라이브러리 → 서드파티 → 로컬

## 3.8. 인터페이스 마이그레이션 가이드

### 3.8.1. Step 인덱싱 변경사항

**이전 (문자열 기반):**
```python
# ❌ 사용하지 마세요
rc.trace_pnl('alpha1', step='ts_mean')
rc.get_intermediate('alpha1', step='ts_mean')
```

**현재 (정수 기반):**
```python
# ✅ 올바른 사용법
rc.trace_pnl('alpha1', step=1)  # step 1까지 추적
rc.get_intermediate('alpha1', step=1)  # step 1 데이터 조회

# 모든 단계 추적
rc.trace_pnl('alpha1')  # step=None (기본값)
# 반환: {0: {...}, 1: {...}, 2: {...}}
```

### 3.8.2. 독립/종속 정렬 패턴

**독립 정렬 (변경 없음):**
```python
# ✅ 기존과 동일하게 작동
rc.add_axis('size', cs_quantile(rc.data.mcap, bins=2, labels=['small','big']))
```

**종속 정렬 (신규 기능):**
```python
# ✅ 새로운 기능
rc.add_axis('value', cs_quantile(rc.data.btm, bins=3, labels=['low','mid','high'],
                                   group_by='size'))
```

**마스크 기반 필터링 (신규 기능):**
```python
# ✅ 새로운 기능
mask = rc.data.volume > threshold
rc.add_axis('filtered', cs_quantile(rc.data.returns, bins=5, labels=[...],
                                      mask=mask))
```

## 3.9. 구현 성공 기준

### 3.9.1. Step 인덱싱 검증

✅ **필수 동작:**
- `rc.trace_pnl('alpha', step=2)` → step 2까지의 PnL 반환
- `rc.get_intermediate('alpha', step=2)` → step 2의 캐시된 DataArray 반환
- 병렬 Expression (브랜치가 있는 트리)에서 올바른 순서로 인덱싱
- 잘못된 step 인덱스 입력 시 명확한 에러 메시지

### 3.9.2. 종속 정렬 검증

✅ **필수 동작:**
- **독립 정렬**: `cs_quantile(...)` → 전체 유니버스 대상 quantile
- **종속 정렬**: `cs_quantile(..., group_by='axis')` → 각 그룹 내 quantile
- **마스크 필터링**: `cs_quantile(..., mask=...)` → 필터링된 부분집합 대상 quantile
- 독립/종속 정렬의 결과 cutoff가 명확히 다름 (검증 테스트 필요)

### 3.9.3. Fama-French 재현 검증

✅ **필수 동작:**
- SMB (독립 2×3 정렬) → 예상된 포트폴리오 가중치 생성
- HML (종속 2×3 정렬) → 예상된 포트폴리오 가중치 생성
- 독립/종속 방식의 cutoff 차이 검증 (academic paper 기준과 일치)

## 3.10. 다음 단계

### Phase 1: 핵심 컴포넌트 구현
- [ ] `Expression` 추상 클래스 및 Leaf/Composite 구현
- [ ] `EvaluateVisitor` 기본 구조 및 캐싱 메커니즘 (정수 step 카운터 포함)
- [ ] `ConfigLoader` 및 YAML 파싱
- [ ] `AlphaCanvas` Facade 기본 구조

### Phase 2: 연산자 구현
- [ ] Timeseries 연산자 (`ts_mean`, `ts_sum`, etc.)
- [ ] Cross-sectional 연산자 (`cs_rank`, `cs_quantile` with `group_by` and `mask`)
- [ ] Transform 연산자 (`group_neutralize`, etc.)

### Phase 3: 추적성 및 분석
- [ ] `PnLTracer` 구현
- [ ] 선택적 단계 추적 로직 (정수 인덱스 기반)
- [ ] 성과 지표 계산
- [ ] PnL 리포트에 step 메타데이터 표시

### Phase 4: 인터페이스 완성
- [ ] Property accessor (`rc.data`, `rc.axis`)
- [ ] NumPy-style 할당 (`rc[mask] = value`)
- [ ] 헬퍼 메서드 (`rc.ts_mean()` 등)

### Phase 5: 검증 및 테스트
- [ ] 정수 step 인덱싱 단위 테스트
- [ ] `_quantile_grouped` 로직 단위 테스트
- [ ] Fama-French SMB/HML 통합 테스트
- [ ] 종속 정렬 성능 벤치마크

---

**참고:** 이 문서는 실제 구현 과정에서 발견되는 새로운 패턴과 교훈을 지속적으로 반영해야 합니다 (Living Document).

